# Resources and Queues: Smart Allocation and Automatic Selection

Now that you understand qxub basics and debugging, let's explore how to specify resources and leverage qxub's intelligent queue selection. qxub makes resource specification simple while providing smart defaults and automatic optimization.

## Understanding Default Resources

Let's first understand what the system provides by default:

```bash
qxub config get defaults.resources
```

**Output:**
```
ğŸ“‹ Configuration: defaults.resources
â””â”€â”€ ['mem=4GB', 'ncpus=1', 'walltime=2:00:00']
```

These defaults work well for:
- Simple scripts and data processing
- Single-threaded applications
- Short-running tasks

## Specifying Custom Resources

### Memory Specification

qxub accepts various memory formats:

```bash
# Request 8GB of memory (also accepts MB: mem=8000MB)
qxub exec --dry --resources mem=8GB -- python analysis.py
```

### CPU Specification

```bash
# Request 4 CPUs for parallel processing
qxub exec --dry --resources ncpus=4 -- python parallel_analysis.py
```

### Walltime Specification

qxub accepts flexible walltime formats:

```bash
# Walltime formats: MM:SS or H:MM:SS
qxub exec --dry --default --resources walltime=1:30:00 -- python long_analysis.py
```

### Combining Resources

```bash
# A job that needs more resources
qxub exec --dry --default --resources mem=16GB,ncpus=4,walltime=4:00:00 -- echo "Resource-intensive job"
```

**Expected dry run output:**
```
ğŸ“‹ Job Configuration:
â”œâ”€â”€ Resources: mem=16GB, ncpus=4, walltime=4:00:00
â”œâ”€â”€ Queue: normal
...
```

## Automatic Queue Selection

One of qxub's most powerful features is automatic queue selection with `--queue auto`:

### Basic Automatic Selection

```bash
# Let qxub choose the best queue
qxub exec --dry --default --queue auto --resources mem=8GB,ncpus=2,walltime=1:00:00 -- echo "Auto queue"
```

**Expected output:**
```
ğŸ¯ Automatic queue selection:
â”œâ”€â”€ Requested: mem=8GB, ncpus=2, walltime=1:00:00
â”œâ”€â”€ Evaluating queues: normal, express, normalsl, hugemem
â”œâ”€â”€ Best match: normal (fits all constraints, lowest cost)
â””â”€â”€ Selected: normal

ğŸ“‹ Job Configuration:
â”œâ”€â”€ Queue: normal
â”œâ”€â”€ Resources: mem=8GB, ncpus=2, walltime=1:00:00
...
```

### Auto Selection for High-Memory Jobs

```bash
# High memory automatically selects appropriate queue
qxub exec --dry --queue auto --resources mem=64GB -- echo "Big memory job"
```

**Expected output:**
```
ğŸ¯ Automatic queue selection:
â”œâ”€â”€ Requested: mem=64GB, ncpus=1, walltime=2:00:00
â”œâ”€â”€ Evaluating queues: normal, express, normalsl, hugemem
â”œâ”€â”€ normal: âŒ Memory limit exceeded (max: ~45GB per CPU)
â”œâ”€â”€ express: âŒ Memory limit exceeded
â”œâ”€â”€ normalsl: âŒ Memory limit exceeded
â”œâ”€â”€ hugemem: âœ… Fits all constraints
â””â”€â”€ Selected: hugemem

ğŸ“‹ Job Configuration:
â”œâ”€â”€ Queue: hugemem
â”œâ”€â”€ Resources: mem=64GB, ncpus=1, walltime=2:00:00
...
```

### Auto Selection for Many CPUs

```bash
# Many CPUs might trigger normalsl selection
qxub exec --dry --queue auto --resources ncpus=32,walltime=2:00:00 -- echo "Many CPU job"
```

qxub analyzes:
- Available CPUs per queue
- Walltime limits for large jobs
- Cost efficiency (SU billing rates)

## Manual Queue Selection

You can also specify queues directly:

### Standard Queues

```bash
# Specify queue directly
qxub exec --dry --queue express --resources mem=8GB,walltime=30:00 -- python analysis.py

# High-memory jobs typically use hugemem queue
qxub exec --dry --queue hugemem --resources mem=128GB -- python big_analysis.py
```

### Understanding Queue Characteristics

Let's see what queues are available:

```bash
qxub platform show-queues
```

**Expected output:**
```
ğŸ“‹ Available Queues (nci_gadi):

normal:
â”œâ”€â”€ Type: standard
â”œâ”€â”€ Max CPUs: 20,736
â”œâ”€â”€ Max Memory: 190GB
â”œâ”€â”€ Max Walltime: 48:00:00
â”œâ”€â”€ SU Rate: 2.0x
â””â”€â”€ Walltime Rules: Shorter for larger jobs

express:
â”œâ”€â”€ Type: standard
â”œâ”€â”€ Max CPUs: 3,168
â”œâ”€â”€ Max Memory: 190GB
â”œâ”€â”€ Max Walltime: 24:00:00
â”œâ”€â”€ SU Rate: 6.0x (premium)
â””â”€â”€ Priority: High

normalsl:
â”œâ”€â”€ Type: shared_memory
â”œâ”€â”€ Max CPUs: 192 per node
â”œâ”€â”€ Max Memory: 1.5TB per node
â”œâ”€â”€ Max Walltime: 48:00:00
â”œâ”€â”€ SU Rate: 2.0x
â””â”€â”€ Use for: Large parallel jobs on single nodes

hugemem:
â”œâ”€â”€ Type: high_memory
â”œâ”€â”€ Max CPUs: 48
â”œâ”€â”€ Max Memory: 1.5TB
â”œâ”€â”€ Max Walltime: 48:00:00
â”œâ”€â”€ SU Rate: 2.0x
â””â”€â”€ Use for: Memory-intensive single-node jobs
```

## Smart Resource Examples

### Data Analysis Job

```bash
# Typical pandas/analysis job
qxub exec --queue auto --resources mem=16GB,ncpus=2,walltime=2:00:00 -- python3 -c "
import pandas as pd
import numpy as np
print('Running data analysis...')
# Simulate some work
import time; time.sleep(5)
print('Analysis complete!')
"
```

### Machine Learning Training

```bash
# ML training with multiple cores
qxub exec --queue auto --resources mem=32GB,ncpus=8,walltime=6:00:00 -- python train_model.py
```

### Quick Test with Express Queue

```bash
# Fast turnaround for debugging
qxub exec --queue express --resources walltime=15:00 -- python quick_test.py
```

## Resource Validation and Warnings

qxub validates your resource requests:

### Over-allocation Warning

```bash
qxub exec --dry --resources mem=200GB --queue normal -- echo "Too much memory"
```

**Expected warning:**
```
âš ï¸  Warning: Requested memory (200GB) exceeds normal queue limit (~190GB)
ğŸ’¡ Suggestion: Use --queue auto or --queue hugemem
ğŸ’¡ Alternative: Reduce memory in --resources to 190GB or less
```

### Walltime vs CPU Rules

```bash
qxub exec --dry --resources ncpus=48,walltime 24:00:00 --queue normal -- echo "Large job"
```

**Expected warning:**
```
âš ï¸  Warning: Large jobs (48+ CPUs) have reduced walltime limits
ğŸ’¡ Max walltime for 48 CPUs: 5:00:00 in normal queue
ğŸ’¡ Suggestion: Reduce walltime in --resources to 5:00:00 or use fewer CPUs
```

## Best Practices

### 1. Start Conservative, Scale Up

```bash
# Start small for testing
qxub exec --dry --resources mem=4GB,walltime=30:00 -- python3 my_script.py

# Scale up after confirming it works
qxub exec --dry --resources mem=16GB,walltime=2:00:00 -- python3 my_script.py
```

### 2. Use Auto Queue Selection

```bash
# Let qxub optimize for you
qxub exec --queue auto --resource mem=8GB,ncpus=4 -- my_analysis.py
```

### 3. Match Resources to Workload

- **I/O intensive**: More memory, fewer CPUs
- **CPU intensive**: More CPUs, standard memory
- **Memory intensive**: High memory, appropriate queue

### 4. Consider Walltime Carefully

```bash
# Better to overestimate slightly than underestimate
qxub exec --resource walltime=1:30:00 -- long_running_task.py  # If you think it takes 1 hour
```

## Monitoring Resource Usage

After jobs complete, qxub shows actual usage:

```bash
qxub exec --resources mem=8GB,walltime=1:00:00 -- python3 -c "
import time
print('Working...')
time.sleep(10)
print('Done!')
"
```

**End of job output:**
```
ğŸ‰ Job completed successfully (exit code: 0)
ğŸ“Š Walltime used: 00:00:15 / 01:00:00 (25% efficiency)
ğŸ’¾ Memory used: 0.3GB / 8.0GB (4% efficiency)
ğŸ’¡ Suggestion: This job could use --resources mem=1GB,walltime=30:00
```

## Key Takeaways

1. **Smart defaults**: The system provides sensible starting points
2. **Flexible formats**: Memory and walltime accept various formats
3. **Auto queue selection**: Use `--queue auto` for optimization
4. **Validation helps**: qxub warns about problematic resource requests
5. **Monitor efficiency**: Learn from actual usage patterns

## Next Steps

Now that you understand resource management:
- **[Execution Contexts](04-execution-contexts.md)** - Using different software environments
- **[Aliases](07-aliases.md)** - Save common resource combinations

Resource specification becomes intuitive with practice. The automatic queue selection feature eliminates much of the guesswork, while the efficiency reporting helps you optimize future jobs.

---

**ğŸ’¡ Pro Tips:**
- Use `--queue auto` unless you have specific queue requirements
- Always use `--dry` to verify resource requests before submitting
- Monitor efficiency reports to optimize future resource allocations
- Start with conservative estimates and scale up based on actual usage
