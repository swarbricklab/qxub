"""
This package provides tools for running qsub jobs on PBS Pro in particular environments.
This avoids boilerplate code for activating environments and switching directories, etc.
In simple cases, the need to create a jobscript can be eliminated entirely.
"""
import os
import sys
from datetime import datetime
import shlex
import time
import logging
import json
from pathlib import Path
import threading
import subprocess
import click
import tailer

import pkg_resources

def setup_logging(verbosity):
    """
    Configures the logging level based on the verbosity provided by the user.

    Args:
        verbosity (int): The number of '-v' flags used. 
                       - 0: ERROR level (default)
                       - 1: WARNING level
                       - 2: INFO level
                       - 3 or more: DEBUG level

    This function adjusts the logging output to provide more detailed information
    as verbosity increases, allowing users to control the granularity of log messages.
    """
    if verbosity == 1:
        logging.basicConfig(level=logging.WARNING)
    elif verbosity == 2:
        logging.basicConfig(level=logging.INFO)
    elif verbosity >= 3:
        logging.basicConfig(level=logging.DEBUG)
    else:
        logging.basicConfig(level=logging.ERROR)

def qsub(cmd):
    """
    Submits a job via qsub based on the given command (cmd)

    Args:
        cmd (chr): qsub command, including all of the options generated by qt

    Returns:
        The job id for the submitted job
    """
    # Make sure that this is a qsub cmd -- don't pass on random commands!
    if not cmd[:4] == "qsub":
        click.echo("Expected qsub comment. Exiting")
        sys.exit(1)
    # pylint: disable=W1510
    result = subprocess.run(shlex.split(cmd),
                            stdout=subprocess.PIPE, stderr=subprocess.PIPE,
                            text=True)
    if result.returncode != 0:
        logging.debug("Job submission failed")
        click.echo(result.stderr)
        sys.exit(result.returncode)
    else:
        logging.debug("Job submitted successfully")
        return result.stdout.rstrip('\n')

def job_status(job_id):
    """
    Parses 'qstat' to determine the status of the job with the given id

    Returns:
        Q: queued
        R: running
        E: ending
        F: finished
        H: held (not enough quota)
    """
    logging.debug("Job id: %s", job_id)
    # pylint: disable=W1510
    qstat_result = subprocess.run(['qstat', '-x', '-f', '-F', 'json', job_id],
                                  stdout=subprocess.PIPE, text=True)
    # Check if qstat failed
    if qstat_result.returncode != 0:
        logging.debug("qstat failed for job %s", job_id)
        click.echo(qstat_result.stderr)
        click.echo(qstat_result.args)
        sys.exit(qstat_result.returncode)
    # Otherwise, extract and return job status from qstat results
    qstat_info = json.loads(qstat_result.stdout)
    logging.debug("Job status: %s", qstat_info)
    status=qstat_info['Jobs'][job_id]['job_state']
    logging.debug("Job status %s", status)
    return status

def monitor_qstat(job_id):
    """
    Monitors for job completion by checking job status periodically
    """
    logging.debug("Waiting 60 seconds before checking job status")
    time.sleep(60)
    logging.debug("Starting job monitoring")
    while True:
        status = job_status(job_id)
        if status in ['F', 'H']:  # Check for job completion
            logging.info("Job %s completed", job_id)
            # stop_event.set()  # Signal the other threads to stop
            sys.exit(0)
        logging.debug("Job %s still running", job_id)
        time.sleep(30)  # Poll every 30 seconds

def tail(log_file, destination):
    """
    Tails the given log_file until either EOF or job completion.
    Output is directed to the specified destination (STDOUT or STDERR)
    """
    if not destination in ['STDOUT', 'STDERR']:
        click.echo("Unknown destination for redirection")
        sys.exit(2)
    is_err = destination == 'STDERR'
    with open(log_file, 'r', encoding='utf-8') as f:
        for line in tailer.follow(f):
            print(line.rstrip(), file=sys.stderr if is_err else sys.stdout)

def monitor_and_tail(job_id, out_file, err_file):
    """
    Monitors the job status using qstat and tails the output (STDOUT and STDERR) logs
    until the job is finished. Stops both tailing and monitoring upon job completion.
    
    Args:
        job_id: The PBS job id to monitor.
        out_file: Path to the STDOUT log file to tail.
        err_file: Path to the STDERR log file to tail.
    """
    # Create threads for job monitoring and log tailing
    qstat_thread = threading.Thread(target=monitor_qstat, args=(job_id,))
    out_thread   = threading.Thread(target=tail, args=(out_file, "STDOUT"), daemon=True)
    err_thread   = threading.Thread(target=tail, args=(err_file, "STDERR"), daemon=True)

    # Start all threads
    qstat_thread.start()
    out_thread.start()
    err_thread.start()
    # Wait for job monitoring to complete
    qstat_thread.join()

@click.group()
@click.option("--execdir",
              default=os.getcwd(),
              help="Execution directory (default: current directory)")
@click.option("--out",
              default=Path(
                  os.getenv("TMPDIR"), "qt", datetime.now().strftime("%Y%m%d_%H%M%S"),"out"),
              help="STDOUT log file (default: $TMPDIR/qt/timestamp/out)")
@click.option("--err",
              default=Path(
                  os.getenv("TMPDIR"), "qt", datetime.now().strftime("%Y%m%d_%H%M%S"),"err"),
              help="STDERR log file (default: $TMPDIR/qt/timestamp/err)")
@click.option("--joblog", help="PBS Pro job log")
@click.option("--dry", "--dry-run", is_flag=True, default=False,
              help="Generate job submission command but don't submit")
@click.option("--quiet", is_flag=True, default=False,
              help="Display no output")
@click.option("-l", "--resources", multiple=True, help="Job resource")
@click.option("-q", "--queue", default="normal", help="Job queue (default: normal)")
@click.option("-N", "--name", default="qt", help="Job name (default: qt)")
@click.option("-P", "--project",
              default=os.getenv("PROJECT"),
              help="PBS project code (default: $PROJECT)")
@click.option("-v", "--verbose", count=True,
              help="Increase verbosity (use -v, -vv, -vvv for more detail)")
@click.pass_context
def qt(ctx, execdir, verbose, **params):
    """
    Parent command 'qt' with options common to all subcommands.
    PBS Pro options (-l,-q,-N,-q) are passed on as parameters to 'qsub'
    but can be specified in either short form (-l) or long form (--resources)

    Run 'qt {subcommand} --help' for details on each subcommand.

    For example: qt conda --help
    """
    setup_logging(verbose)
    logging.debug("Execution directory: %s", execdir)
    for key, value in params.items():
        logging.debug("qsub option: %s = %s", key, value)
    ctx.ensure_object(dict)
    # Construct the qsub options
    joblog = params['joblog'] or f"{params['name']}.log"
    options = "-N {name} -q {queue} -P {project} ".format_map(params)
    options += " ".join([f"-l {resource}" for resource in params['resources']])
    options += f" -o {joblog}"
    logging.info("Options: %s", options)
    # Load qsub options into context
    ctx.obj['execdir'] = execdir
    ctx.obj['options'] = options
    ctx.obj['name'] = params['name']
    ctx.obj['out'] = params['out']
    ctx.obj['err'] = params['err']
    ctx.obj['dry'] = params['dry']
    ctx.obj['quiet'] = params['quiet']

@qt.command()
@click.argument("cmd", nargs=-1)
@click.option("--env",
              default=os.getenv('CONDA_DEFAULT_ENV'),
              help="Conda environment to use (default: active environment)")
@click.option("--template",
              default=pkg_resources.resource_filename(__name__, 'jobscripts/qconda.pbs'),
              help="Jobscript template (optional - for further customization)")
@click.pass_context
def conda(ctx, cmd, env, template):
    """
    Constructs and submits a qsub job that will execute the given command
    in the specified conda environment and work directory

    Example:
        qt --resources mem=50MB conda --env myenv -- python --version

    Here the command "python --version" will run in the "myenv" conda environment
    with 50MB of RAM. See "qt --help" for other resource options.

    Note the "--" before the command. This is required if command itself also
    contains double-dashes, as in this case ("--version").
    """
    # Get values from context
    execdir = ctx.obj['execdir']
    options = ctx.obj['options']
    out = Path(ctx.obj['out'])
    err = Path(ctx.obj['err'])
    dry = ctx.obj['dry']
    quiet = ctx.obj['quiet']
    # Log parameters and context
    for key, value in ctx.obj.items():
        logging.debug("Context: %s = %s", key, value)
    logging.debug("Conda environment: %s", env)
    logging.debug("Jobscript template: %s", template)
    logging.debug("Command: %s", cmd)
    # Construct qsub command
    full_cmd = " ".join(cmd)
    submission_command = f'qsub -v env={env},cmd="{full_cmd}",cwd={execdir},'
    submission_command+= f'out={out},err={err} {options} {template}'
    # Execute the command
    logging.info("Submission command: %s", submission_command)
    if dry:
        logging.info("Dry run. Exiting")
        sys.exit(0)
    logging.info("Submitting job")
    job_id=qsub(submission_command)
    logging.info("Your job has been successfully submitted")
    # Exit if in quiet mode
    if quiet:
        logging.info("Exiting in quiet mode")
        sys.exit(0)

    # Start concurrent monitoring of job and log files
    # Stream log files to STDOUT/STDERR as appropriate
    Path(out).parent.mkdir(parents=True, exist_ok=True)
    Path(err).parent.mkdir(parents=True, exist_ok=True)
    out.touch()
    err.touch()
    monitor_and_tail(job_id, out, err)
