"""
This package provides tools for running qsub jobs on PBS Pro in particular environments.
This avoids boilerplate code for activating environments and switching directories, etc.
In simple cases, the need to create a jobscript can be eliminated entirely.
"""
import sys
import shlex
import time
import logging
import json
import threading
import subprocess
import click
import tailer


def print_status(message, final=False):
    """Print a status message that overwrites the previous one"""
    if final:
        # Final message - print normally and move to next line
        print(f"\r{message}" + " " * 20)
    else:
        # Temporary message - overwrite without newline
        print(f"\r{message}", end="", flush=True)


class JobSpinner:
    """Context manager for displaying a spinner during job operations."""
    
    def __init__(self, message="", quiet=False, show_message=True):
        self.message = message
        self.quiet = quiet
        self.show_message = show_message
        self.spinner_chars = "⠋⠙⠹⠸⠼⠴⠦⠧⠇⠏"
        self.spinning = False
        self.thread = None
        self.original_line_len = 0
    
    def _spin(self):
        """Run the spinner animation"""
        i = 0
        while self.spinning:
            char = self.spinner_chars[i % len(self.spinner_chars)]
            if self.show_message:
                line = f"{self.message} {char}"
                print(f"\r{line}", end="", flush=True)
                self.original_line_len = len(line)
            else:
                print(f" {char}", end="", flush=True)
            time.sleep(0.1)
            i += 1
    
    def __enter__(self):
        if not self.quiet:
            self.spinning = True
            self.thread = threading.Thread(target=self._spin)
            self.thread.daemon = True
            self.thread.start()
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        if not self.quiet and self.spinning:
            self.spinning = False
            if self.thread:
                self.thread.join(timeout=0.2)
            # Clear the spinner line completely
            clear_line = " " * (self.original_line_len + 5)
            print(f"\r{clear_line}\r", end="", flush=True)


def qsub(cmd, quiet=False):
    """
    Submits a job via qsub based on the given command (cmd)

    Args:
        cmd (chr): qsub command, including all of the options generated by qt
        quiet (bool): whether to suppress spinner output

    Returns:
        The job id for the submitted job
    """
    # Make sure that this is a qsub cmd -- don't pass on random commands!
    if not cmd[:4] == "qsub":
        click.echo("Expected qsub comment. Exiting")
        sys.exit(1)
    
    with JobSpinner(show_message=False, quiet=quiet):
        # pylint: disable=W1510
        result = subprocess.run(shlex.split(cmd),
                                stdout=subprocess.PIPE, stderr=subprocess.PIPE,
                                text=True)
        if result.returncode != 0:
            logging.debug("Job submission failed")
            click.echo(result.stderr)
            sys.exit(result.returncode)
        else:
            logging.debug("Job submitted successfully")
            return result.stdout.rstrip('\n')

def job_status(job_id):
    """
    Parses 'qstat' to determine the status of the job with the given id

    Returns:
        Q: queued
        R: running
        E: ending
        F: finished
        H: held (not enough quota)
    """
    logging.debug("Job id: %s", job_id)
    # pylint: disable=W1510
    qstat_result = subprocess.run(['qstat', '-x', '-f', '-F', 'json', job_id],
                                  stdout=subprocess.PIPE, text=True)
    # Check if qstat failed
    if qstat_result.returncode != 0:
        logging.debug("qstat failed for job %s", job_id)
        click.echo(qstat_result.stderr)
        click.echo(qstat_result.args)
        sys.exit(qstat_result.returncode)
    # Otherwise, extract and return job status from qstat results
    qstat_info = json.loads(qstat_result.stdout)
    logging.debug("Job status: %s", qstat_info)
    status=qstat_info['Jobs'][job_id]['job_state']
    logging.debug("Job status %s", status)
    return status

def monitor_qstat(job_id, quiet=False):
    """
    Monitors for job completion by checking job status periodically
    """
    logging.debug("Waiting 60 seconds before checking job status")
    
    with JobSpinner("Waiting for job to start...", show_message=True, quiet=quiet):
        time.sleep(60)
    
    logging.debug("Starting job monitoring")
    
    while True:
        status = job_status(job_id)
        if status in ['F', 'H']:  # Check for job completion
            logging.info("Job %s completed", job_id)
            # Job completed - exit silently (user can check qstat if needed)
            sys.exit(0)
        logging.debug("Job %s still running", job_id)
        # Sleep without showing any status messages
        time.sleep(30)  # Poll every 30 seconds

def tail(log_file, destination):
    """
    Tails the given log_file until either EOF or job completion.
    Output is directed to the specified destination (STDOUT or STDERR)
    """
    if not destination in ['STDOUT', 'STDERR']:
        click.echo("Unknown destination for redirection")
        sys.exit(2)
    is_err = destination == 'STDERR'
    with open(log_file, 'r', encoding='utf-8') as f:
        for line in tailer.follow(f):
            print(line.rstrip(), file=sys.stderr if is_err else sys.stdout)

def monitor_and_tail(job_id, out_file, err_file, quiet=False):
    """
    Monitors the job status using qstat and tails the output (STDOUT and STDERR) logs
    until the job is finished. Stops both tailing and monitoring upon job completion.
    
    Args:
        job_id: The PBS job id to monitor.
        out_file: Path to the STDOUT log file to tail.
        err_file: Path to the STDERR log file to tail.
        quiet: Whether to suppress spinner output.
    """
    # Create threads for job monitoring and log tailing
    qstat_thread = threading.Thread(target=monitor_qstat, args=(job_id, quiet))
    out_thread   = threading.Thread(target=tail, args=(out_file, "STDOUT"), daemon=True)
    err_thread   = threading.Thread(target=tail, args=(err_file, "STDERR"), daemon=True)

    # Start all threads
    qstat_thread.start()
    out_thread.start()
    err_thread.start()
    # Wait for job monitoring to complete
    qstat_thread.join()
