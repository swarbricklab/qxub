"""
This package provides tools for running qsub jobs on PBS Pro in particular environments.
This avoids boilerplate code for activating environments and switching directories, etc.
In simple cases, the need to create a jobscript can be eliminated entirely.
"""
import sys
import shlex
import time
import logging
import json
import threading
import subprocess
import click
import tailer


def qsub(cmd):
    """
    Submits a job via qsub based on the given command (cmd)

    Args:
        cmd (chr): qsub command, including all of the options generated by qt

    Returns:
        The job id for the submitted job
    """
    # Make sure that this is a qsub cmd -- don't pass on random commands!
    if not cmd[:4] == "qsub":
        click.echo("Expected qsub comment. Exiting")
        sys.exit(1)
    # pylint: disable=W1510
    result = subprocess.run(shlex.split(cmd),
                            stdout=subprocess.PIPE, stderr=subprocess.PIPE,
                            text=True)
    if result.returncode != 0:
        logging.debug("Job submission failed")
        click.echo(result.stderr)
        sys.exit(result.returncode)
    else:
        logging.debug("Job submitted successfully")
        return result.stdout.rstrip('\n')

def job_status(job_id):
    """
    Parses 'qstat' to determine the status of the job with the given id

    Returns:
        Q: queued
        R: running
        E: ending
        F: finished
        H: held (not enough quota)
    """
    logging.debug("Job id: %s", job_id)
    # pylint: disable=W1510
    qstat_result = subprocess.run(['qstat', '-x', '-f', '-F', 'json', job_id],
                                  stdout=subprocess.PIPE, text=True)
    # Check if qstat failed
    if qstat_result.returncode != 0:
        logging.debug("qstat failed for job %s", job_id)
        click.echo(qstat_result.stderr)
        click.echo(qstat_result.args)
        sys.exit(qstat_result.returncode)
    # Otherwise, extract and return job status from qstat results
    qstat_info = json.loads(qstat_result.stdout)
    logging.debug("Job status: %s", qstat_info)
    status=qstat_info['Jobs'][job_id]['job_state']
    logging.debug("Job status %s", status)
    return status

def monitor_qstat(job_id):
    """
    Monitors for job completion by checking job status periodically
    """
    logging.debug("Waiting 60 seconds before checking job status")
    time.sleep(60)
    logging.debug("Starting job monitoring")
    while True:
        status = job_status(job_id)
        if status in ['F', 'H']:  # Check for job completion
            logging.info("Job %s completed", job_id)
            # stop_event.set()  # Signal the other threads to stop
            sys.exit(0)
        logging.debug("Job %s still running", job_id)
        time.sleep(30)  # Poll every 30 seconds

def tail(log_file, destination):
    """
    Tails the given log_file until either EOF or job completion.
    Output is directed to the specified destination (STDOUT or STDERR)
    """
    if not destination in ['STDOUT', 'STDERR']:
        click.echo("Unknown destination for redirection")
        sys.exit(2)
    is_err = destination == 'STDERR'
    with open(log_file, 'r', encoding='utf-8') as f:
        for line in tailer.follow(f):
            print(line.rstrip(), file=sys.stderr if is_err else sys.stdout)

def monitor_and_tail(job_id, out_file, err_file):
    """
    Monitors the job status using qstat and tails the output (STDOUT and STDERR) logs
    until the job is finished. Stops both tailing and monitoring upon job completion.
    
    Args:
        job_id: The PBS job id to monitor.
        out_file: Path to the STDOUT log file to tail.
        err_file: Path to the STDERR log file to tail.
    """
    # Create threads for job monitoring and log tailing
    qstat_thread = threading.Thread(target=monitor_qstat, args=(job_id,))
    out_thread   = threading.Thread(target=tail, args=(out_file, "STDOUT"), daemon=True)
    err_thread   = threading.Thread(target=tail, args=(err_file, "STDERR"), daemon=True)

    # Start all threads
    qstat_thread.start()
    out_thread.start()
    err_thread.start()
    # Wait for job monitoring to complete
    qstat_thread.join()
